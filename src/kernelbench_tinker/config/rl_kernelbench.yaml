# KernelBench RL Training Configuration (Integration Default)
# =============================================================
#
# Default config for the KernelBench â†” Tinker integration.
#
# Required Environment Variables:
#   TINKER_API_KEY       - Tinker distributed training API key
#   MODAL_TOKEN_ID       - Modal API token ID (for isolated GPU evaluation)
#   MODAL_TOKEN_SECRET   - Modal API token secret
#
# Usage:
#   python -m kernelbench_tinker.scripts.train_kernel_rl \
#       --config src/kernelbench_tinker/config/rl_kernelbench.yaml \
#       log_path=./runs/my_experiment

# =============================================================================
# Model Configuration
# =============================================================================
model_name: "Qwen/Qwen3-30B-A3B"
lora_rank: 64
learning_rate: 0.000002

# =============================================================================
# Generation Configuration
# =============================================================================
max_tokens: 16384
temperature: 1.0

# =============================================================================
# Training Configuration
# =============================================================================
num_substeps: 2
loss_fn: "importance_sampling"

# KL Regularization (optional)
kl_penalty_coef: 0.0
kl_discount_factor: 0.0

# Remove groups with constant rewards (no learning signal)
remove_constant_reward_groups: true

# =============================================================================
# Logging and Checkpointing
# =============================================================================
log_path: "./runs/kernelbench_tinker"
save_every: 1
eval_every: 10

# Weights & Biases (optional)
wandb_project: null
wandb_name: null

# =============================================================================
# Dataset Configuration
# =============================================================================
dataset_builder:
    # Problem selection
    level: 1
    start_problem: null
    end_problem: null
    backend: "triton"
    dataset_src: "huggingface"

    # Training configuration
    batch_size: 8
    group_size: 16
    num_epochs: 22
    shuffle: true

    # Evaluation configuration
    num_correct_trials: 5
    measure_performance: true
    timing_method: "cuda_event"
    precision: "fp32"
    check_for_excessive_speedup: true
    excessive_speedup_threshold: 10.0
    kernel_eval_build_dir: null

    # Reward configuration
    reward_format_weight: 0.0
    reward_compile_weight: 0.0
    reward_correctness_weight: 0.3
    reward_speed_weight: 1.0
    reward_length_weight: 0.0

    # Test split
    test_fraction: 0.1

    # Renderer (should match model)
    renderer_name: "qwen3"

    # Prompt configuration
    prompt_option: "one_shot"
    prompt_precision: null
    prompt_include_hardware: false
    prompt_gpu_name: null

    # =============================================================================
    # Modal Configuration (Isolated GPU Evaluation)
    # Run each kernel in an isolated Modal container with hard timeout
    # =============================================================================
    use_modal: true
    modal_gpu_type: "A100"
    modal_timeout: 60.0
